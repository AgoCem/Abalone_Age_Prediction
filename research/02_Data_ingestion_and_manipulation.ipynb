{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this code we will perform the data ingestion and manipulation that will be later used in the modular project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing core libraries\n",
    "\n",
    "import os \n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\agost\\\\Data_Career\\\\End_to_end_projects\\\\Abalone_Age_Prediction'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionManipulationConfig:\n",
    "    root_dir: Path\n",
    "    local_data_file: Path\n",
    "    source_URL: str\n",
    "    save_training_file: Path\n",
    "    param_target_col: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Abalone_Age_Prediction.utils.common import create_directories, read_yaml, save_data\n",
    "from Abalone_Age_Prediction.constants import *\n",
    "from Abalone_Age_Prediction import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                 config_filepath = CONFIG_FILE_PATH,\n",
    "                 params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root]) #the artifacts_root is the key of the dictionary created\n",
    "                                                # in the yaml file and we can read this key like that instead of\n",
    "                                                # [\"artifacts_root\"] because we used the ConfigBox in the common.py file\n",
    "\n",
    "\n",
    "    def get_data_ingestion_config(self) -> DataIngestionManipulationConfig:\n",
    "        config = self.config.data_ingestion_manipulation #data ingestion is the other key value of the dictionary in the config.yaml file\n",
    "\n",
    "        create_directories([config.root_dir,config.save_training_file])\n",
    "\n",
    "        data_ingestion_manipulation_config = DataIngestionManipulationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            local_data_file = config.local_data_file,\n",
    "            source_URL = config.source_URL,\n",
    "            save_training_file= config.save_training_file,\n",
    "            param_target_col=self.params.TARGET\n",
    "        )                                     \n",
    "\n",
    "        return data_ingestion_manipulation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestionManipulation:\n",
    "    def __init__(self, config: DataIngestionManipulationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def download_file(self):\n",
    "        \"\"\"\n",
    "        file_path: str\n",
    "        Download, if it doesn't already exists, the csv file with data, don't need a return, just to save the Data\n",
    "        \"\"\"\n",
    "        if not os.path.exists(self.config.local_data_file):\n",
    "            filename, headers = request.urlretrieve(\n",
    "                url = self.config.source_URL,\n",
    "                filename= self.config.local_data_file\n",
    "            )\n",
    "\n",
    "            #logger.info(f\"{filename} is downloading with the following info: \\n{headers}\")\n",
    "        else:\n",
    "            logger.info(f\"File already downloaded\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def read_file(self):\n",
    "        \"\"\"\n",
    "        Read the csv file\n",
    "        \"\"\"\n",
    "        try:\n",
    "            \n",
    "            raw_data = pd.read_csv(self.config.local_data_file)\n",
    "\n",
    "            return raw_data\n",
    "\n",
    "        except Exception as e:\n",
    "            e\n",
    "\n",
    "    def preprocess_file(self,raw_data):\n",
    "        \"\"\"\n",
    "        Preprocess the data and save it into a training and testing files\n",
    "        \"\"\"\n",
    "\n",
    "        numerical_cols = raw_data.select_dtypes(include='number').columns\n",
    "        categorical_cols = raw_data.select_dtypes(include='object').columns\n",
    "\n",
    "        \n",
    "\n",
    "        for col in categorical_cols:\n",
    "            encoder = LabelEncoder()\n",
    "            raw_data[col] = encoder.fit_transform(raw_data[col])\n",
    "\n",
    "        X = raw_data.drop(labels = self.config.param_target_col, axis = 1)\n",
    "        y = raw_data[self.config.param_target_col]\n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "        numerical_cols = numerical_cols.drop(self.config.param_target_col)\n",
    "        X[numerical_cols] = scaler.fit_transform(X[numerical_cols])\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,random_state=10)\n",
    "\n",
    "        train_data = pd.concat([X_train,y_train],axis = 1)\n",
    "        test_data = pd.concat([X_test,y_test],axis = 1)\n",
    "\n",
    "        training_path = self.config.save_training_file\n",
    "        #print(\"Before\")\n",
    "        save_data(Path(training_path),train_data,\"train.csv\")\n",
    "        #print(\"After\")\n",
    "        save_data(Path(training_path),test_data,\"test.csv\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\agost\\\\Data_Career\\\\End_to_end_projects\\\\Abalone_Age_Prediction'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-13 23:27:42,138: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-06-13 23:27:42,140: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-06-13 23:27:42,141: INFO: common: created directory at: artifacts]\n",
      "[2024-06-13 23:27:42,141: INFO: common: created directory at: artifacts/data_ingestion]\n",
      "[2024-06-13 23:27:42,141: INFO: common: created directory at: artifacts/training]\n",
      "[2024-06-13 23:27:42,141: INFO: 770311276: File already downloaded]\n",
      "      Sex    Length  Diameter    Height  Whole weight  Shucked weight  \\\n",
      "3544    1  0.540541  0.504202  0.110619      0.171596        0.144250   \n",
      "2751    0  0.594595  0.571429  0.119469      0.182044        0.134835   \n",
      "4019    2  0.790541  0.773109  0.137168      0.509828        0.473773   \n",
      "997     2  0.695946  0.697479  0.141593      0.426421        0.321453   \n",
      "2523    0  0.662162  0.647059  0.132743      0.347441        0.300269   \n",
      "...   ...       ...       ...       ...           ...             ...   \n",
      "2009    1  0.479730  0.445378  0.097345      0.129449        0.111970   \n",
      "1180    2  0.783784  0.773109  0.141593      0.463255        0.371217   \n",
      "3441    0  0.527027  0.504202  0.101770      0.165929        0.130800   \n",
      "1344    2  0.689189  0.697479  0.146018      0.498318        0.537323   \n",
      "1289    1  0.581081  0.571429  0.092920      0.194440        0.166106   \n",
      "\n",
      "      Viscera weight  Shell weight  \n",
      "3544        0.144832      0.140010  \n",
      "2751        0.173140      0.159940  \n",
      "4019        0.467413      0.332337  \n",
      "997         0.318631      0.306428  \n",
      "2523        0.309414      0.246139  \n",
      "...              ...           ...  \n",
      "2009        0.133641      0.103139  \n",
      "1180        0.485188      0.342302  \n",
      "3441        0.154707      0.124066  \n",
      "1344        0.300856      0.292476  \n",
      "1289        0.134957      0.168909  \n",
      "\n",
      "[3341 rows x 8 columns]\n",
      "3544     9\n",
      "2751     9\n",
      "4019    10\n",
      "997      8\n",
      "2523     9\n",
      "        ..\n",
      "2009     8\n",
      "1180    11\n",
      "3441     7\n",
      "1344    10\n",
      "1289     8\n",
      "Name: Rings, Length: 3341, dtype: int64\n",
      "[2024-06-13 23:27:42,176: INFO: common: File train.csv saved]\n",
      "[2024-06-13 23:27:42,181: INFO: common: File test.csv saved]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_ingestion_manipulation_config = config.get_data_ingestion_config()\n",
    "    data_ingestion_manipulation = DataIngestionManipulation(config=data_ingestion_manipulation_config)\n",
    "    data_ingestion_manipulation.download_file()\n",
    "    data = data_ingestion_manipulation.read_file()\n",
    "    data_ingestion_manipulation.preprocess_file(data)\n",
    "    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
